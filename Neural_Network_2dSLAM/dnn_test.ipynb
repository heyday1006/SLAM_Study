{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "dnn_test_pose.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heyday1006/2D-Lidar-DNN/blob/main/dnn_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diihcLRnplal"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os, re, math, json, shutil, pprint\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewlqIm0Xplan"
      },
      "source": [
        "# Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usB_F5S5plao"
      },
      "source": [
        "import pickle5 as pickle\n",
        "from numpy import linalg as LA\n",
        "import math\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def read_from_pickle(dir_name,world_name,size_change):\n",
        "    print(os.path.exists(dir_name+'/'+world_name+'_range_pairs.pickle'))\n",
        "    with open(dir_name+'/'+world_name+'_range_pairs.pickle', 'rb') as handle:\n",
        "        range_pairs_all = pickle.load(handle)\n",
        "\n",
        "    with open(dir_name+'/'+world_name+'_pose_rels.pickle', 'rb') as handle:\n",
        "        pose_rels_all = pickle.load(handle)\n",
        "    range_pairs = np.swapaxes(range_pairs_all, 1, 2)\n",
        "    translation_rels=np.round(np.double(pose_rels_all[:,0:2]),4)\n",
        "    rotation_rels=np.double(pose_rels_all[:,2])\n",
        "    if size_change:\n",
        "        range_pairs = range_pairs[:,::2,:]\n",
        "        range_pairs = range_pairs[:,90:451,:]\n",
        "    print(\"size of range_pairs: \", range_pairs.shape)\n",
        "    print(\"size of pose_rels: \", translation_rels.shape)\n",
        "    print(\"size of rotation_rels: \", rotation_rels.shape)\n",
        "    print(\"<------------->\")\n",
        "    return range_pairs,translation_rels,rotation_rels\n",
        "\n",
        "testing_range_pairs,testing_translation_rels,testing_rotation_rels = read_from_pickle('ros_data','custom_officetwo',True)\n",
        "# testing_range_pairs,testing_translation_rels,testing_rotation_rels = read_from_pickle('benchmark_csail_0403','benchmark_csail',False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvrKfC27plap"
      },
      "source": [
        "testing_pose_rels_all=np.hstack((testing_translation_rels,np.expand_dims(testing_rotation_rels, axis=1)))\n",
        "#print(np.shape(range_pairs_compressed),np.shape(pose_rels_grid),np.shape(rotation_rels_grid),np.shape(pose_rels_grid_all),np.shape(pose_rels_all))\n",
        "testing_range_pairs_all=np.clip(testing_range_pairs, a_min=None, a_max=40)    #remove the inf value of range to a large number\n",
        "nonzero_indices = np.where((LA.norm(testing_pose_rels_all[:,0:2], axis=1)>1e-4) | (np.abs(testing_pose_rels_all[:,2])>1e-4))\n",
        "x_test_new, y_test_new, y_test_new_ground_truth = (testing_range_pairs_all[nonzero_indices[0][0]:nonzero_indices[0][-1]],testing_pose_rels_all[nonzero_indices[0][0]:nonzero_indices[0][-1]], testing_pose_rels_all[nonzero_indices[0][0]:nonzero_indices[0][-1]])\n",
        "\n",
        "x_pose_testing = np.array(x_test_new, dtype=float)\n",
        "y_pose_testing = np.array(y_test_new, dtype=float)\n",
        "print('Size of testing data: ', x_pose_testing.shape)\n",
        "print('Size of testing labels: ',y_pose_testing.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4qLK7W-plap"
      },
      "source": [
        "nonzero_indices[0][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh1unv9Hplap"
      },
      "source": [
        "# DL MODEL (Pose Regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY2nzZ4eplaq"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "pose_testing_dataset = tf.data.Dataset.from_tensor_slices((x_pose_testing, (y_pose_testing[:,0:2],y_pose_testing[:,2]))).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tol2qQAzplaq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, Activation, MaxPooling1D, Add, AveragePooling1D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def residual_block(x):\n",
        "        temp = x\n",
        "        x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "        x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
        "        x = Add()([Activation('relu')(x), temp])\n",
        "        return x\n",
        "\n",
        "def Res1DFlat_Pose(dropout_rate,input_shape):\n",
        "    # input size = (batch_size, 2, 1081)\n",
        "    input_data = Input(shape=input_shape)\n",
        "    #x = Dense(1024, activation='relu')(1081)\n",
        "    # first resnet block\n",
        "    x = Conv1D(filters=64, kernel_size=7, strides=3, activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling1D(pool_size=3)(x)\n",
        "    x=residual_block(x)\n",
        "    # second resnet block\n",
        "    x=residual_block(x)\n",
        "    # third resnet block\n",
        "    x=residual_block(x)\n",
        "    # fourth resnet block\n",
        "    x=residual_block(x)\n",
        "    # fifth resnet block\n",
        "    x=residual_block(x)\n",
        "\n",
        "    # Average pooling\n",
        "    x = AveragePooling1D(pool_size=7)(x)\n",
        "    x = Flatten()(x) # (batch_size, 2, channel)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x1 = Dense(512, activation='relu')(x)\n",
        "    x1 = Dropout(dropout_rate)(x1)\n",
        "    #output1 = Dense(2786, activation='softmax', name='pose')(x1)\n",
        "    output1 = Dense(2, activation=None, name='pose')(x1)\n",
        "\n",
        "    x2 = Dense(512, activation='relu')(x)\n",
        "    x2 = Dropout(dropout_rate)(x2)\n",
        "    output2 = Dense(1, activation=None,name='rotation')(x2)\n",
        "    #x2 = Dense(230, activation='softmax')(x2)\n",
        "    #output2 = SoftArgmax(name='rotation')(x2,10)#Dense(230, activation='softmax', name='rotation')(x2)\n",
        "\n",
        "    model = Model(inputs=input_data, outputs=[output1, output2])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfiXsahNplaq"
      },
      "source": [
        "import zipfile\n",
        "import gdown\n",
        "# !gdown --id 1El4hPKw0Fn71kYD3Tj_fsdP3pVPjOUbI\n",
        "# local_zip = 'model_weights_0404_361samples.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('model_weights_0404_361samples')\n",
        "# zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pml2yMC7plar"
      },
      "source": [
        "dropout_rate=0.2\n",
        "pose_model = Res1DFlat_Pose(dropout_rate,np.shape(x_pose_testing[0]))\n",
        "optimizer_lr=0.001\n",
        "optimizer = tf.keras.optimizers.Adam(optimizer_lr)\n",
        "pose_model.compile(optimizer=optimizer,\n",
        "              loss={\"pose\": keras.losses.mse, \"rotation\": keras.losses.mse},#sparse_categorical_crossentropy,losses.mse},\n",
        "              loss_weights=[10.0, 0.05],\n",
        "              metrics={\"pose\": tf.keras.metrics.MeanAbsoluteError(), \"rotation\": tf.keras.metrics.MeanAbsoluteError()})#SparseCategoricalAccuracy,MeanAbsoluteError()})\n",
        "# pose_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_WyHhGvplar"
      },
      "source": [
        "pose_model.load_weights('model_weights_0404_361samples/model_weights_0404_361samples/base_model_weights')\n",
        "pose_model.evaluate(pose_testing_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8kr6x-iplar"
      },
      "source": [
        "from matplotlib.animation import FuncAnimation\n",
        "def edge_angle(yaw_j,yaw_jc):\n",
        "    heading_j=np.array([[np.cos(yaw_j),np.sin(yaw_j)]]).T\n",
        "    heading_jc=np.array([[np.cos(yaw_jc),np.sin(yaw_jc)]]).T\n",
        "    cAngle=np.dot(heading_j.T,heading_jc)\n",
        "    sAngle=np.dot(np.array([[0,0,1]]),np.cross(np.append(heading_j,0),np.append(heading_jc,0)))\n",
        "    #print(np.shape(cAngle),np.shape(sAngle))\n",
        "    edgeAngle=np.arctan2(sAngle,cAngle)\n",
        "    return edgeAngle\n",
        "\n",
        "def rels_to_abs(pose_rels,pose_init):\n",
        "    pose_i = np.reshape(pose_init,(3,1))\n",
        "    poses = pose_i.T\n",
        "    theta_i = pose_init[2]\n",
        "    for i in range(pose_rels.shape[0]):\n",
        "        [rels_x,rels_y,rels_theta] = pose_rels[i,0:3]\n",
        "        T_matrix = np.array([[np.cos(theta_i),-np.sin(theta_i)],[np.sin(theta_i),np.cos(theta_i)]])\n",
        "        if isinstance(rels_theta,np.ndarray):\n",
        "            theta_i += rels_theta[0,0]\n",
        "        else:\n",
        "            theta_i += rels_theta\n",
        "        translation_ic = np.dot(T_matrix,np.reshape(list([rels_x,rels_y]),(2,1)))+pose_i[0:2]\n",
        "        pose_ic =np.concatenate((translation_ic[0],translation_ic[1],[theta_i]),axis=0)[:,np.newaxis]\n",
        "        poses = np.concatenate((poses,pose_ic.T))\n",
        "        pose_i = pose_ic       \n",
        "    return poses\n",
        "trajectory_true = rels_to_abs(np.array(y_pose_testing),np.array([0,0,0]))#casil: [0.154,0.068,0.562729]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux0vZy_Iplas"
      },
      "source": [
        "rels_to_abs(np.array(y_pose_testing[0:2]),np.array([0,0,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trdqLSUoplas"
      },
      "source": [
        "def posePredict(pose_model, x_pose_testing):\n",
        "    pose_predict_raw=pose_model.predict(x_pose_testing)\n",
        "    pose_predict_translation_value = np.array(pose_predict_raw[0])\n",
        "#     print(np.array(tf.squeeze(pose_predict_raw[1])),np.array(tf.squeeze(pose_predict_raw[1])).shape)\n",
        "    pose_predict_rotation_value=np.expand_dims(np.array(tf.squeeze(pose_predict_raw[1])), axis=1)*np.pi/180\n",
        "    pose_predict = np.concatenate((pose_predict_translation_value,pose_predict_rotation_value),axis=-1)\n",
        "    return np.array(pose_predict)\n",
        "def display_posePredict(pose_model, x_pose_testing, y_pose_testing, nSamples,print_interval):\n",
        "    pose_predict = posePredict(pose_model, x_pose_testing)\n",
        "    for i in range(nSamples):\n",
        "        predict_i=list(np.round(pose_predict[i,0:2],4))\n",
        "        predict_i.append(np.round(float(pose_predict[i,2]),4))\n",
        "        if i%print_interval==0:\n",
        "            print(\"test: \", i, \" ground_truth: \", np.round(np.double(y_pose_testing[i,:]),4),\n",
        "              \" predicted: \",predict_i)\n",
        "    return pose_predict\n",
        "pose_predict = display_posePredict(pose_model, x_pose_testing, y_pose_testing, nSamples=y_pose_testing.shape[0],print_interval=50)\n",
        "trajectory_estimate = rels_to_abs(np.array(pose_predict),np.array([0,0,0]))#casil: [0.154,0.068,0.562729]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG2CBgglplat"
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(range(x_pose_testing.shape[1]),x_pose_testing[0,:,0])\n",
        "plt.plot(range(x_pose_testing.shape[1]),x_pose_testing[0,:,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFmBTWQmplat"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "def trajectory_plot(poses,ax):\n",
        "#    plt.figure()\n",
        "    colors = iter(cm.rainbow(np.linspace(1, 0, poses.shape[0] + 1)))\n",
        "    for count in range(poses.shape[0]):\n",
        "        if count % 2 == 0:\n",
        "            ax.scatter(poses[count,0], poses[count,1], color=next(colors), s=35)\n",
        "        if count == 9000:\n",
        "            break\n",
        "    ax.scatter(poses[0,0], poses[0,1], color='r', s=500)\n",
        "    ax.scatter(poses[-1,0], poses[-1,1], color=next(colors), s=500)\n",
        "    ax.plot(poses[:,0], poses[:,1])\n",
        "plt.figure(1)\n",
        "#    poses = poses[0:2,:]\n",
        "ax1=plt.subplot(121)\n",
        "trajectory_plot(trajectory_true[:,:2],ax1)\n",
        "ax2=plt.subplot(122,sharex=ax1,sharey=ax1)\n",
        "trajectory_plot(trajectory_estimate[:,:2],ax2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtJHjOjLplau"
      },
      "source": [
        "# with open('simple_maze5_pose_rels_estimate.pickle', 'wb') as handle:\n",
        "#     pickle.dump(np.array(pose_predict), handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPZSeEi3plau"
      },
      "source": [
        "# DL Model (Loop Closure)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcM4nRo9plau"
      },
      "source": [
        "def Res1DFlat_Closure(dropout_rate,input_shape):\n",
        "    # input size = (batch_size, 2, 1081)\n",
        "    input_data = Input(shape=input_shape)\n",
        "    #x = Dense(1024, activation='relu')(1081)\n",
        "    # first resnet block\n",
        "    x = Conv1D(filters=64, kernel_size=7, strides=3, activation='relu', padding='same')(input_data)\n",
        "    x = MaxPooling1D(pool_size=3)(x)\n",
        "    x=residual_block(x)\n",
        "    # second resnet block\n",
        "    x=residual_block(x)\n",
        "    # third resnet block\n",
        "    x=residual_block(x)\n",
        "    # fourth resnet block\n",
        "    x=residual_block(x)\n",
        "    # fifth resnet block\n",
        "    x=residual_block(x)\n",
        "\n",
        "    # Average pooling\n",
        "    x = AveragePooling1D(pool_size=7)(x)\n",
        "    x = Flatten()(x) # (batch_size, 2, channel)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x3 = Dense(512, activation='relu')(x)\n",
        "    x3 = Dropout(dropout_rate)(x3)\n",
        "    output3 = Dense(1, activation='sigmoid',name='closure')(x3)\n",
        "    model = Model(inputs=input_data, outputs=[output3])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag0F_YlFplav"
      },
      "source": [
        "# import zipfile\n",
        "# import gdown\n",
        "# !gdown --id 12Rz-4UxQLl-4riabQb7t_jw543ABfTYD\n",
        "# local_zip = 'detection_model_weights_0404_361samples.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('detection_model_weights_0404_361samples')\n",
        "# zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtRDeLoDplav"
      },
      "source": [
        "detection_model = Res1DFlat_Closure(dropout_rate,np.shape(x_pose_testing[0]))\n",
        "optimizer = tf.keras.optimizers.Adam(optimizer_lr)\n",
        "detection_model.compile(optimizer=optimizer,\n",
        "              loss={ \"closure\":keras.losses.BinaryCrossentropy()},#sparse_categorical_crossentropy,losses.mse},\n",
        "              metrics={ \"closure\":[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()]})#SparseCategoricalAccuracy,MeanAbsoluteError()})\n",
        "# detection_model.summary()\n",
        "detection_model.load_weights('detection_model_weights_0411_361samples/base_model_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyJd_fMaplaw"
      },
      "source": [
        "def closure_condtion_check(y_pose_testing):\n",
        "    closure_indices=np.where((LA.norm(y_pose_testing[:,0:2], axis=1)<0.6) & (np.abs(y_pose_testing[:,2])<70*np.pi/180))\n",
        "    return closure_indices\n",
        "\n",
        "def closure_ground_truth_from_pose_rels(y_pose_testing):\n",
        "    closure_indices = closure_condtion_check(y_pose_testing)\n",
        "    closure_mask=np.zeros((y_pose_testing.shape[0],1),dtype=bool)\n",
        "    closure_mask[closure_indices,:]=True\n",
        "    y_closure_testing=closure_mask\n",
        "    return y_closure_testing\n",
        "\n",
        "def closure_pos_neg_rate(y_closure_testing):\n",
        "    neg, pos = np.bincount(np.array(y_closure_testing[:,0]))\n",
        "    total = neg + pos\n",
        "    print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "        total, pos, 100 * pos / total))\n",
        "\n",
        "def closurePredict(detection_model, x_closure_testing):\n",
        "    closure_predict=detection_model.predict(x_closure_testing)>0.5\n",
        "    return closure_predict\n",
        "\n",
        "def display_closurePredidct(detection_model, x_closure_testing,y_closure_testing, nSamples,print_interval,display):\n",
        "    BATCH_SIZE = 32\n",
        "    detection_testing_dataset = tf.data.Dataset.from_tensor_slices((x_closure_testing, y_closure_testing)).batch(BATCH_SIZE)\n",
        "    detection_model.evaluate(detection_testing_dataset)\n",
        "    closure_predict = closurePredict(detection_model, x_closure_testing)\n",
        "    if display:\n",
        "        for i in range(nSamples):\n",
        "            if i%print_interval==0:\n",
        "                print(\"test: \", i, \" ground_truth: \", y_closure_testing[i], \" predicted: \",closure_predict[i])\n",
        "    return closure_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hEWyq_xplaw"
      },
      "source": [
        "def closure_check(detection_model):\n",
        "    testing_range_pairs,testing_translation_rels,testing_rotation_rels = read_from_pickle('ros_data','simple_maze_closure',True)\n",
        "    testing_pose_rels_all=np.hstack((testing_translation_rels,np.expand_dims(testing_rotation_rels, axis=1)))\n",
        "    #print(np.shape(range_pairs_compressed),np.shape(pose_rels_grid),np.shape(rotation_rels_grid),np.shape(pose_rels_grid_all),np.shape(pose_rels_all))\n",
        "    testing_range_pairs_all=np.clip(testing_range_pairs, a_min=None, a_max=40)    #remove the inf value of range to a large number\n",
        "    nonzero_indices = np.where((LA.norm(testing_pose_rels_all[:,0:2], axis=1)>1e-4) | (np.abs(testing_pose_rels_all[:,2])>1e-4))\n",
        "    # nonfar_indices=np.where((testing_rotation_rels<=1.0) & (testing_rotation_rels>=-1.0) )\n",
        "    # chosen_indices=np.intersect1d(nonzero_indices,nonfar_indices)\n",
        "    chosen_indices = nonzero_indices\n",
        "    x_test_new, y_test_new, y_test_new_ground_truth = (testing_range_pairs_all[chosen_indices],testing_pose_rels_all[chosen_indices], testing_pose_rels_all[chosen_indices])\n",
        "    y_pose_testing = np.array(y_test_new, dtype=float)\n",
        "    x_closure_testing = x_test_new\n",
        "    y_closure_testing = closure_ground_truth_from_pose_rels(y_pose_testing)\n",
        "    print(x_closure_testing.shape,y_closure_testing.shape)#,np.array(y_closure_testing[:,0]).shape)\n",
        "    closure_pos_neg_rate(y_closure_testing)\n",
        "    closure_predict = display_closurePredidct(detection_model, x_closure_testing,y_closure_testing, nSamples=y_closure_testing.shape[0], print_interval=500, display=False)\n",
        "closure_check(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1o5bNtrplaw"
      },
      "source": [
        "# Pose Graph Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esuL89GUplaw"
      },
      "source": [
        "def abs_to_rels(pose_j,pose_jc):\n",
        "    pose_delta=[]\n",
        "    [x_j,y_j,yaw_j]=pose_j\n",
        "    [x_jc,y_jc,yaw_jc]=pose_jc\n",
        "    x_delta=(x_jc-x_j)*np.cos(yaw_j) + (y_jc-y_j)*np.sin(yaw_j)\n",
        "    y_delta=(y_jc-y_j)*np.cos(yaw_j) - (x_jc-x_j)*np.sin(yaw_j)\n",
        "    yaw_delta=edge_angle(yaw_j,yaw_jc)\n",
        "    return [x_delta,y_delta,yaw_delta[0,0]]\n",
        "\n",
        "# def trajectory_to_closure_candidates(trajectory_estimate):\n",
        "#     # find out loop closure candidates\n",
        "#     closure_candidates = []\n",
        "#     for i in range(0,trajectory_estimate.shape[0]-15):\n",
        "#         for j in range(i+15,trajectory_estimate.shape[0]):\n",
        "#             pose_i = trajectory_estimate[i]\n",
        "#             pose_j = trajectory_estimate[j]\n",
        "#             pose_ij = abs_to_rels(pose_j,pose_i)\n",
        "#     #         print(pose_ij[0:2])\n",
        "#             if (LA.norm(pose_ij[0:2])<0.3) & (np.abs(pose_ij[2])<40*np.pi/180):\n",
        "#                 closure_candidates.append([i,j])\n",
        "#     closure_candidates = np.array(closure_candidates)\n",
        "#     return closure_candidates\n",
        "\n",
        "\n",
        "def closure_candidates_extensive(trajectory):\n",
        "    closure_candidates = []\n",
        "    for i in range(0, trajectory.shape[0]-20):\n",
        "        for j in range(i+20, trajectory.shape[0]):\n",
        "            closure_candidates.append([i,j])\n",
        "    closure_candidates = np.array(closure_candidates)\n",
        "    return closure_candidates\n",
        "\n",
        "def pose_rels_from_trajectory(trajectory, closure_candidates):\n",
        "    y_pose_testing = np.zeros((closure_candidates.shape[0],trajectory.shape[1]))\n",
        "    for i in range(closure_candidates.shape[0]):\n",
        "        y_pose_testing[i] = abs_to_rels(trajectory[closure_candidates[i,0]],trajectory[closure_candidates[i,1]])\n",
        "    return y_pose_testing\n",
        "\n",
        "def closure_ground_truth_from_trajectory(trajectory, closure_candidates):\n",
        "    y_pose_testing = pose_rels_from_trajectory(trajectory, closure_candidates)\n",
        "    closure_indices = closure_condtion_check(y_pose_testing)\n",
        "    closure_mask=np.zeros((y_pose_testing.shape[0],1),dtype=bool)\n",
        "    closure_mask[closure_indices,:]=True\n",
        "    y_closure_testing=closure_mask\n",
        "    return y_closure_testing          \n",
        "\n",
        "def closure_candidates_scan_pairs(trajectory_estimate, testing_range_pairs, closure_candidates):\n",
        "    # create loop closure candiates scan pairs\n",
        "    laser_scans = np.zeros((trajectory_estimate.shape[0],testing_range_pairs.shape[1]))\n",
        "    for i in range(trajectory_estimate.shape[0]-1):\n",
        "        laser_scans[i] = testing_range_pairs[i,:,0]\n",
        "    laser_scans[-1] = testing_range_pairs[-1,:,1]\n",
        "    closure_range_pairs = []\n",
        "    for i in range(closure_candidates.shape[0]):\n",
        "        closure_range_pairs.append(laser_scans[closure_candidates[i],:])\n",
        "    print(np.array(closure_range_pairs).shape)\n",
        "    closure_range_pairs = np.swapaxes(np.array(closure_range_pairs), 1, 2)\n",
        "    return closure_range_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjQcdDETplax"
      },
      "source": [
        "def closure_candidates_filter(trajectory_estimate,trajectory_true, x_pose_testing):\n",
        "    closure_candidates = closure_candidates_extensive(trajectory_estimate)\n",
        "    closure_range_pairs = closure_candidates_scan_pairs(trajectory_estimate, x_pose_testing, closure_candidates)\n",
        "    # print(closure_candidates.T, closure_range_pairs.shape)\n",
        "    x_closure_testing = closure_range_pairs\n",
        "    y_closure_testing = closure_ground_truth_from_trajectory(trajectory_true, closure_candidates)\n",
        "    print(\"number of closure candidates using naive method: \", closure_candidates.shape[0])\n",
        "#     closure_pos_neg_rate(y_closure_testing)\n",
        "    # print(y_closure_testing)\n",
        "    closure_predict = display_closurePredidct(detection_model, x_closure_testing,y_closure_testing, nSamples=x_closure_testing.shape[0], print_interval=100, display=False)\n",
        "    # filter out outliers\n",
        "    closure_candidates_with_outliers = closure_candidates[np.where(closure_predict==True)[0]]\n",
        "    print(\"number of closures before removing outliers: \", closure_candidates_with_outliers.shape[0])\n",
        "    pose_rels_odometry = pose_rels_from_trajectory(trajectory_estimate, closure_candidates_with_outliers)\n",
        "    closure_indices = closure_condtion_check(pose_rels_odometry)\n",
        "    closure_candidates_without_outliers = closure_candidates_with_outliers[closure_indices]\n",
        "    closure_range_pairs = closure_candidates_scan_pairs(trajectory_estimate, x_pose_testing, closure_candidates_without_outliers)\n",
        "    print(\"number of closures after removing outliers: \", closure_candidates_without_outliers.shape[0])\n",
        "    x_closure_testing = closure_range_pairs\n",
        "    y_closure_testing = closure_ground_truth_from_trajectory(trajectory_true, closure_candidates_without_outliers)\n",
        "    closure_predict = display_closurePredidct(detection_model, x_closure_testing,y_closure_testing, nSamples=x_closure_testing.shape[0], print_interval=5, display=True)\n",
        "    #from pose regressor find closure relative pose\n",
        "    closure_pose_candidates = closure_candidates_without_outliers[:,[1, 0]]\n",
        "    closure_pose_y_testing = pose_rels_from_trajectory(trajectory_true,closure_pose_candidates)\n",
        "    closure_pose_x_testing = closure_candidates_scan_pairs(trajectory_estimate, x_pose_testing, closure_pose_candidates)\n",
        "    closure_pose_predict = display_posePredict(pose_model, closure_pose_x_testing, closure_pose_y_testing, nSamples=closure_pose_y_testing.shape[0],print_interval=10)\n",
        "    return closure_pose_candidates, closure_pose_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqwX4ruhplax"
      },
      "source": [
        "closure_pose_candidates, closure_pose_predict = closure_candidates_filter(trajectory_estimate,trajectory_true, x_pose_testing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efv5IUcoplay"
      },
      "source": [
        "closure_pose_candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkBTQ7QMplay"
      },
      "source": [
        "closure_candidates_without_outliers = closure_pose_candidates\n",
        "test_idx = closure_candidates_without_outliers[3]\n",
        "test_range_sample=np.concatenate((x_pose_testing[test_idx[0],:,0][np.newaxis, :, np.newaxis],x_pose_testing[test_idx[1],:,0][np.newaxis, :, np.newaxis]),axis=-1)\n",
        "test_odometry_sample=pose_rels_from_trajectory(trajectory_estimate, np.array([[test_idx[0],test_idx[1]]]))\n",
        "closure_predict = closurePredict(detection_model, test_range_sample)\n",
        "print(test_odometry_sample,closure_predict)\n",
        "plt.figure(1)\n",
        "#    poses = poses[0:2,:]\n",
        "ax1=plt.subplot(121)\n",
        "trajectory_plot(trajectory_true[:,:2],ax1)\n",
        "for i in range(closure_candidates_without_outliers.shape[0]):\n",
        "    test_idx = closure_candidates_without_outliers[i]\n",
        "    ax1.scatter(trajectory_true[test_idx,0],trajectory_true[test_idx,1],color='g',s=20)\n",
        "    \n",
        "ax2=plt.subplot(122,sharex=ax1,sharey=ax1)\n",
        "trajectory_plot(trajectory_estimate[:,:2],ax2)\n",
        "for i in range(closure_candidates_without_outliers.shape[0]):\n",
        "    test_idx = closure_candidates_without_outliers[i]\n",
        "    ax2.scatter(trajectory_estimate[test_idx,0],trajectory_estimate[test_idx,1],color='g',s=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-xB0zrXplay"
      },
      "source": [
        "import gtsam\n",
        "import matplotlib.pyplot as plt\n",
        "import gtsam.utils.plot as gtsam_plot\n",
        "def vector3(x, y, z):\n",
        "    \"\"\"Create 3d double numpy array.\"\"\"\n",
        "    return np.array([x, y, z], dtype=float)\n",
        "\n",
        "def pose_graph_construct(pose_predict,trajectory_estimate,closure_pose_candidates,closure_pose_predict):\n",
        "    # Create noise models\n",
        "    PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(vector3(0.05, 0.05, 0.1))\n",
        "    ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(vector3(0.05, 0.05, 0.1))\n",
        "    # 1. Create a factor graph container and add factors to it\n",
        "    graph = gtsam.NonlinearFactorGraph()\n",
        "    # 2b. Add odometry factors\n",
        "    # A prior factor consists of a mean and a noise ODOMETRY_NOISE (covariance matrix)\n",
        "    graph.add(gtsam.PriorFactorPose2(1, gtsam.Pose2(0, 0, 0), PRIOR_NOISE))\n",
        "    # graph.add(gtsam.NonlinearEqualityPose2())\n",
        "    # Create odometry (Between) factors between consecutive poses\n",
        "    pose_predict=np.array(pose_predict)\n",
        "    for i in range(pose_predict.shape[0]-1):\n",
        "        pos_rel = pose_predict[i+1]\n",
        "        graph.add(gtsam.BetweenFactorPose2(i+1, i+2, gtsam.Pose2(pos_rel[0],pos_rel[1], pos_rel[2]), ODOMETRY_NOISE))\n",
        "    # print(\"\\nFactor Graph:\\n{}\".format(graph))  # print\n",
        "    # 2c. Add the loop closure constraint\n",
        "    # This factor encodes the fact that we have returned to the same pose. In real\n",
        "    # systems, these constraints may be identified in many ways, such as appearance-based\n",
        "    # techniques with camera images. We will use another Between Factor to enforce this constraint:\n",
        "    closure_pose_candidates_new = closure_pose_candidates + 1\n",
        "    for i in range(closure_pose_candidates.shape[0]):\n",
        "        graph.add(gtsam.BetweenFactorPose2(\n",
        "            closure_pose_candidates_new[i,0], closure_pose_candidates_new[i,1], gtsam.Pose2(closure_pose_predict[i,0],closure_pose_predict[i,1],closure_pose_predict[i,2]), ODOMETRY_NOISE))\n",
        "    # 3. Create the data structure to hold the initial_estimate estimate to the\n",
        "    # solution. use odometry estimation as the initial estimate (nonconvex: initial matters)\n",
        "    initial_estimate = gtsam.Values()\n",
        "    for i in range(trajectory_estimate.shape[0]):\n",
        "        initial_estimate.insert(i+1, gtsam.Pose2(trajectory_estimate[i,0], trajectory_estimate[i,1], trajectory_estimate[i,2]))\n",
        "    # print(\"\\nInitial Estimate:\\n{}\".format(initial_estimate))  # print\n",
        "    return graph, initial_estimate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eckbz8wpplaz"
      },
      "source": [
        "def pose_graph_optimization(graph, initial_estimate):\n",
        "    # 4. Optimize the initial values using a Gauss-Newton nonlinear optimizer\n",
        "    # The optimizer accepts an optional set of configuration parameters,\n",
        "    # controlling things like convergence criteria, the type of linear\n",
        "    # system solver to use, and the amount of information displayed during\n",
        "    # optimization. We will set a few parameters as a demonstration.\n",
        "    parameters = gtsam.GaussNewtonParams()\n",
        "\n",
        "    # Stop iterating once the change in error between steps is less than this value\n",
        "    parameters.setRelativeErrorTol(1e-5)\n",
        "    # Do not perform more than N iteration steps\n",
        "    parameters.setMaxIterations(100)\n",
        "    # Create the optimizer ... # other optimizers LM\n",
        "    optimizer = gtsam.GaussNewtonOptimizer(graph, initial_estimate, parameters)\n",
        "    # ... and optimize\n",
        "    result = optimizer.optimize()\n",
        "    # print(\"Final Result:\\n{}\".format(result))\n",
        "\n",
        "    resultPoses = gtsam.utilities.extractPose2(result)\n",
        "#     for i in range(resultPoses.shape[0]):\n",
        "#         gtsam_plot.plot_pose2(1, gtsam.Pose2(resultPoses[i, :]))\n",
        "#     plt.show()\n",
        "    return resultPoses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX5_LtZNplaz"
      },
      "source": [
        "graph,initial_estimate = pose_graph_construct(pose_predict,trajectory_estimate,closure_pose_candidates,closure_pose_predict)\n",
        "resultPoses = pose_graph_optimization(graph, initial_estimate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_dciOTplaz"
      },
      "source": [
        "ax1=plt.subplot(131)\n",
        "trajectory_plot(trajectory_true[:,:2],ax1)\n",
        "plt.scatter(trajectory_true[test_idx,0],trajectory_true[test_idx,1],color='g',s=100)\n",
        "ax2=plt.subplot(132)\n",
        "trajectory_plot(trajectory_estimate[:,:2],ax2)\n",
        "plt.scatter(trajectory_estimate[test_idx,0],trajectory_estimate[test_idx,1],color='g',s=100)\n",
        "ax3=plt.subplot(133,sharex=ax1,sharey=ax1)\n",
        "trajectory_plot(resultPoses[:,:2],ax3)\n",
        "plt.scatter(resultPoses[test_idx,0],resultPoses[test_idx,1],color='g',s=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E404dCK3plaz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}